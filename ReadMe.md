# About
Use Apache Spark to Perform ETL on big data  at the scale, We practice the following topics to implement on most projects focusing on [Pandas API on Spark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/index.html) that make it easier for you to move from developing on Pasdas to Spark.
* [Spark SQL](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html)
* [Pandas API on Spark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/index.html)
* [Structured Streaming](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ss/index.html)
* [ Dataproc Serverless](https://cloud.google.com/dataproc-serverless/docs/overview)
## Tutorial Reference
* [PySpark Tutorial By Examples](https://sparkbyexamples.com/pyspark-tutorial/) | [github pyspark-examples](https://github.com/spark-examples/pyspark-examples)
* [Getting Started with Spark](https://spark.apache.org/docs/latest/api/python/getting_started/index.html)
* [Getting Started with Spark on Databricks](https://www.databricks.com/spark/getting-started-with-apache-spark)
* [serverless-spark-workshop](https://github.com/GoogleCloudPlatform/serverless-spark-workshop)

